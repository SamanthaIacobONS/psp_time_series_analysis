{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Public Service Productivity - Residual Analysis for Autocorrelation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The Office for National Statistics partners with government departments, academics and subject matter experts to review public service productivity. This is a measure of public sector input against outputs. Inputs include labour, goods and services used for work and capital, and outputs vary from department to department but include things like operations for the NHS or court hearings for the Ministry of Justice. For some (but currently not all) departments, these outputs are further modified by quality metrics: for the Department of Education for instance, more students means higher output and therefore higher productivity as long as inputs (teachers, educational funding) remain constant. However overcrowded classrooms can lead to lower exam grades which would mean it is counterproductive. Adjusting the productivity index accounts for this and avoids misleading productivity figures. \n",
    "\n",
    "This data is produced annually but the work involved in assessing the quality adjustments means there is a significant lag. Alongside this, closely related data is produced quarterly with a lag of only four months. This is not adjusted for quality so it is available quite promptly, but it does not perfectly align to the annual data due to difference in reporting areas.\n",
    "\n",
    "The ONS's Time Series Analysis team uses the annual figures for inputs and outputs as well as the quarterly data to nowcast public sector productivity figures. The dynamic regression model they use for this is more complex (and therefore more expensive and time consuming to run) than simpler models available. The use of this model is based on an assumption that residuals from this model are not correlated over time which means that there is no information left in the residuals â€“ it is all accounted for by the model.\n",
    "\n",
    "The main goal of this project is to examine this assumption by analysising the data to see whether using a simpler model, the residuals are correlated over time. The hypothesis is that they will be, and showing this will prove that the current method of forecasting is justified. However if the hypothesis is shown to be false this opens up the opportunity for time and cost savings in preparing the forecasts in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the data\n",
    "\n",
    "We've been provided with the data used to train the Nowcast models and an R Script which uses the annual and annualised quartly PSP data to generate Nowcasts based on each model for each individual PSP variable tracked by the team (Totals, Education, Health and Public Order & Safety). \n",
    "\n",
    "These figures are represented as a proportion of the 1997 baseline, which is set to 100 (so a score of 200 for inputs would represent a doubling of 1997 inputs). They are saved in the \"data/nowcast\" directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating lists\n",
    "categories = [\"Total\", \"Health\", \"Education\", \"POS\"]\n",
    "measures = [\"Input\", \"Output\", \"Productivity\"]\n",
    "inputs = [x + \"_\" + measures[0] for x in categories]\n",
    "outputs = [x + \"_\" + measures[1] for x in categories]\n",
    "prods = [x + \"_\" + measures[2] for x in categories]\n",
    "models = ['observed', 'cagr', 'ets','dynamic','growth_rate']\n",
    "cutoff_year = 2007 #data before this cutoff will be ignored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Select target below:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = inputs # IMPORTANT! Select from inputs, outputs or prods here e.g. target = inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "def data_importer(metric, cutoff = cutoff_year):\n",
    "    '''\n",
    "    Takes the metric you are interested in (from one of the lists above) and imports it to a df\n",
    "    with a datetime index. The metric's nowcast data must be in the data/nowcast directory\n",
    "    '''\n",
    "    df = pd.read_csv(f\"data/nowcast/PSP_TSC-V_{metric}.csv\")\n",
    "    df.rename(columns = {\"Unnamed: 0\": \"year\"}, inplace = True)\n",
    "    df.year += 1996 \n",
    "    df.year = pd.to_datetime(df.year, format='%Y')\n",
    "    df = df.set_index('year')\n",
    "    df = df[df.index >= f'{cutoff}/01/01']\n",
    "    df = df.dropna(axis = 1)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_all = [] # creating an empty list to catch all the dataframes for each target variable\n",
    "for i, variable in enumerate(target):\n",
    "    df_all.append(data_importer(target[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, df in enumerate(df_all):\n",
    "    print('#' * 30)\n",
    "    print(target[i])\n",
    "    print('#' * 30)\n",
    "    display(df_all[i].describe())\n",
    "    display(df_all[i].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def initial_plot(df, metric, models_list = models):\n",
    "    ''' Creates a plot of the Nowcasts and obs of the metric of interest.'''\n",
    "    plt.figure(figsize =(8, 6))\n",
    "    for model in models_list:\n",
    "        try:\n",
    "            plt.plot(df[model], label = model)\n",
    "        except KeyError: \n",
    "            pass\n",
    "    \n",
    "    plt.title(f'PSP {metric} Nowcasts by model, baseline 1997 = 100')\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('Year')\n",
    "    plt.legend()\n",
    "    \n",
    "\n",
    "for i, df in enumerate(df_all):\n",
    "        initial_plot(df_all[i], target[i], models) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Augmented Dickey-Fuller Test** (statistical method to detect if a time series is stationary).\n",
    "\n",
    "If p > 0.05 the series is not stationary (ie. it displays a trend or seasonality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i,df in enumerate(df_all):\n",
    "    print(\"Models,\", target[i],':') \n",
    "    print('-' * 30)\n",
    "    for model in models:\n",
    "        try:\n",
    "            adf_result = adfuller(df_all[i][model])\n",
    "            print(model,'p-value:', adf_result[1])\n",
    "        except KeyError:\n",
    "            print(f'p-value not available for {target[i]} {model} model.')\n",
    "    print(\"\\n\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residuals plots\n",
    "\n",
    "As the data shows very little sign of seasonality it was not possible to extract residuals from the trend using the seasonal decompose method. Instead we decided to do the following for each variable:\n",
    "\n",
    "* Fit a linear line of best fit to that data\n",
    "* Plot the residuals based on their distance from this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Function to perform linear regression and plot results\n",
    "def plot_regression(df, ax_data, ax_residuals, X, y, label):\n",
    "    # Fitting the linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    # Calculating residuals\n",
    "    residuals = y - y_pred\n",
    "    \n",
    "    # Plotting the data and the line of best fit\n",
    "    ax_data.plot(df.index, y, label='Nowcast')\n",
    "    ax_data.plot(df.index, y_pred, label='Line of Best Fit', color='red')\n",
    "    ax_data.set_xlabel('Year')\n",
    "    ax_data.set_ylabel(label)\n",
    "    ax_data.set_title(f'{label} vs Year with Line of Best Fit')\n",
    "    ax_data.legend()\n",
    "    \n",
    "    # Plotting residuals\n",
    "    ax_residuals.scatter(df.index, residuals, label='Residuals')\n",
    "    ax_residuals.axhline(0, color='red', linestyle='--', label='Zero Line')\n",
    "    ax_residuals.set_xlabel('Date')\n",
    "    ax_residuals.set_ylabel('Residuals')\n",
    "    ax_residuals.set_title(f'Residuals of {label} vs Year')\n",
    "    ax_residuals.legend()\n",
    "\n",
    "for i, entry in enumerate(df_all):\n",
    "    print('#' * 30)\n",
    "    print(\"Variable :\", target[i])\n",
    "    print('#' * 30)\n",
    "    fig, axs = plt.subplots(5, 2, figsize=(12, 16))\n",
    "    fig.tight_layout(pad=6.0)\n",
    "\n",
    "    # Loop through model columns\n",
    "    for j, model in enumerate(models):\n",
    "        X = np.arange(len(df_all[i])).reshape(-1, 1)  # Reshape to fit the model\n",
    "\n",
    "        # Plot for model data\n",
    "        try:\n",
    "            y_input = df_all[i][model].values\n",
    "            plot_regression(df_all[i],axs[j, 0], axs[j, 1], X, y_input, model)\n",
    "        except KeyError:\n",
    "            print(f'Data not available for {target[i]} {model}.')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADF Test on the residuals\n",
    "\n",
    "The Augmented Dickey-Fuller (ADF) test is performed on the residuals of regression models fitted to the various time series data. The ADF test helps determine whether these residuals are stationary, which is essential for validating the adequacy of the time series models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform ADF test\n",
    "def perform_adf_test(series):\n",
    "    \"\"\"Perform the ADF test on a time series and return results.\"\"\"\n",
    "    result = adfuller(series)\n",
    "    adf_statistic = result[0]\n",
    "    p_value = result[1]\n",
    "    critical_values = result[4]\n",
    "    return adf_statistic, p_value, critical_values\n",
    "\n",
    "# Initialize an empty list to collect dataframes\n",
    "adf_results = []\n",
    "for i, entry in enumerate(df_all):\n",
    "    # Initialize an empty list to collect results\n",
    "    results = []\n",
    "\n",
    "    # Loop through each column to fit a regression model and get residuals\n",
    "    for column in models:\n",
    "        # Prepare the data for regression\n",
    "        try:\n",
    "            y = df_all[i][column]\n",
    "            X = sm.add_constant(range(len(y)))  # Use time index as the independent variable\n",
    "        except KeyError:\n",
    "            print(f'ADF Test not available for {target[i]} residuals.')\n",
    "        else:\n",
    "            # Fit the model\n",
    "            model = sm.OLS(y, X).fit()\n",
    "\n",
    "            # Get the residuals\n",
    "            residuals = model.resid\n",
    "\n",
    "            # Perform ADF test on the residuals\n",
    "            adf_statistic, p_value, critical_values = perform_adf_test(residuals)\n",
    "    \n",
    "            # Store results in the list\n",
    "            results.append({\n",
    "                'Model': column,\n",
    "                'ADF Statistic': adf_statistic,\n",
    "                'ADF p-value': p_value,\n",
    "                'ADF Critical Value (1%)': critical_values['1%'],\n",
    "                'ADF Critical Value (5%)': critical_values['5%'],\n",
    "                'ADF Critical Value (10%)': critical_values['10%']\n",
    "        })\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    adf_results.append(pd.DataFrame(results))\n",
    "\n",
    "    # Print the results DataFrame\n",
    "    print(target[i])\n",
    "    display(adf_results[i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Statistics:\n",
    "- ADF Statistic: This is the test statistic from the ADF test. The more negative this value, the stronger the evidence against the null hypothesis of a unit root (i.e., non-stationarity).\n",
    "- p-value: The probability that the test statistic is as extreme as observed under the null hypothesis. A low p-value (typically below 0.05) indicates that the null hypothesis can be rejected, suggesting that the residuals are stationary.\n",
    "- Critical Values (1%, 5%, 10%): These are the threshold values for the ADF Statistic at different significance levels. If the ADF Statistic is more negative than the critical value at a particular significance level, the null hypothesis is rejected at that level.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ljung-Box Test\n",
    "This tests the overall randomness of autocorrelations in a time series. It checks for the absence of serial autocorrelations.\n",
    "The null hypothesis is that the model does not show a lack of fit - that any residuals are white noise. On the other hand if the null hyptothesis is rejected the model shows a lack of fit : there is data left on the table that should be incorporated into the model. a low P value (< 0.05) would be grounds to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Function to perform Ljung-Box test and return results\n",
    "def perform_ljung_box_test(residuals, lags=[10]):\n",
    "    \"\"\"Perform the Ljung-Box test on residuals and return results as DataFrame.\"\"\"\n",
    "    ljung_box_result = acorr_ljungbox(residuals, lags=lags, return_df=True)\n",
    "    return ljung_box_result\n",
    "#collecting overall results\n",
    "ljung_box_results = [] \n",
    "for i, entry in enumerate(df_all):\n",
    "    # Collect results\n",
    "    results = []\n",
    "\n",
    "    for model in models:\n",
    "        try:\n",
    "            y = df_all[i][model]\n",
    "            \n",
    "        except KeyError:\n",
    "            print(f'Ljung-Box Test results not available for {target[i]} {model} model.')\n",
    "        \n",
    "        else:\n",
    "            X = sm.add_constant(range(len(y)))  # Time index as independent variable\n",
    "            lbmodel = sm.OLS(y, X).fit()\n",
    "            residuals = lbmodel.resid\n",
    "            ljung_box_result = perform_ljung_box_test(residuals, lags=[10])\n",
    "            results.append({\n",
    "                'Model': model,\n",
    "                'Ljung-Box Statistic': ljung_box_result['lb_stat'].values[0],\n",
    "                'Ljung-Box p-value': ljung_box_result['lb_pvalue'].values[0]\n",
    "        })\n",
    "\n",
    "    # Create DataFrame from results\n",
    "    ljung_box_results.append(pd.DataFrame(results))\n",
    "\n",
    "    # Print the results DataFrame\n",
    "    print(target[i])\n",
    "    display(ljung_box_results[i])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ljung-Box Results Explained\n",
    "The results presented are from the Ljung-Box test, which is a statistical test used to check if there are significant autocorrelations (dependencies) in the residuals of a time series model. The test essentially checks whether the residuals are randomly distributed (i.e., if they are \"white noise\"). If the residuals exhibit significant autocorrelation, it suggests that the model may not have fully captured the underlying structure of the data.\n",
    "\n",
    "### Key Statistics:\n",
    "- Ljung-Box Statistic: This is the test statistic calculated by the Ljung-Box test for each variable. A higher value of this statistic indicates more significant autocorrelation in the residuals.\n",
    "- p-value: The p-value associated with the Ljung-Box statistic. It represents the probability of observing the data if the null hypothesis (that there is no autocorrelation) is true. A low p-value (typically below 0.05) suggests that we should reject the null hypothesis, indicating the presence of significant autocorrelation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output (save ADF and Ljung-Box data by variable to multi-tab .xlsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning a name variable here\n",
    "if target == inputs:\n",
    "    name = \"inputs\"\n",
    "elif target == outputs:\n",
    "    name = \"outputs\"\n",
    "elif target == prods:\n",
    "    name = \"productivity\"\n",
    "\n",
    "\n",
    "#creating an excel file with tabs for each variable analysed\n",
    "outcome = []\n",
    "for i, entry in enumerate(df_all):\n",
    "    outcome.append(adf_results[i].merge(ljung_box_results[i], how='left', on='Model'))\n",
    "\n",
    "try:\n",
    "    with pd.ExcelWriter(f\"output/{name}_results.xlsx\") as writer:\n",
    "        for i, entry in enumerate(outcome):\n",
    "            outcome[i].to_excel(writer, sheet_name=target[i])   \n",
    "    print(f\"Results output to 'output/{name}_results.xlsx'\")\n",
    "except:        \n",
    "    print(f\"Error: The file 'output/{name}_results.xlsx' is currently open. Please close it and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summaries of ADF and Ljung-Box Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f'output/{name}_results.xlsx' \n",
    "excel_file = pd.ExcelFile(file_path)\n",
    "\n",
    "# Output .txt file path\n",
    "output_file_path = f'output/{name}_summaries.txt'\n",
    "\n",
    "# Function to interpret ADF results\n",
    "def interpret_adf(row):\n",
    "    if row['ADF p-value'] < 0.01:\n",
    "        return 'strong evidence of stationarity'\n",
    "    elif row['ADF p-value'] < 0.05:\n",
    "        return 'evidence of stationarity'\n",
    "    elif row['ADF p-value'] < 0.10:\n",
    "        return 'borderline stationarity'\n",
    "    else:\n",
    "        return 'non-stationary residuals'\n",
    "\n",
    "# Function to interpret Ljung-Box results\n",
    "def interpret_ljung_box(row):\n",
    "    if row['Ljung-Box p-value'] < 0.01:\n",
    "        return 'significant autocorrelation'\n",
    "    elif row['Ljung-Box p-value'] < 0.05:\n",
    "        return 'moderate autocorrelation'\n",
    "    else:\n",
    "        return 'weak autocorrelation'\n",
    "\n",
    "# Open the text file\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    # Go through each sheet in the Excel file\n",
    "    for sheet_name in excel_file.sheet_names:\n",
    "        df = excel_file.parse(sheet_name)\n",
    "        \n",
    "        # Summaries\n",
    "        adf_summary = []\n",
    "        ljung_box_summary = []\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            adf_result = interpret_adf(row)\n",
    "            ljung_box_result = interpret_ljung_box(row)\n",
    "            \n",
    "            adf_summary.append(f\"{row['Model']}: {adf_result}\")\n",
    "            ljung_box_summary.append(f\"{row['Model']}: {ljung_box_result}\")\n",
    "        \n",
    "        # Summary strings\n",
    "        adf_summary_str = f\"### ADF Test Summary for {sheet_name}:\\n\" + \"\\n\".join([f\"- {summary}\" for summary in adf_summary])\n",
    "        ljung_box_summary_str = f\"\\n### Ljung-Box Test Summary for {sheet_name}:\\n\" + \"\\n\".join([f\"- {summary}\" for summary in ljung_box_summary])\n",
    "        \n",
    "        # Print the summary for the current sheet\n",
    "        print(adf_summary_str)\n",
    "        print(ljung_box_summary_str)\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "        \n",
    "        # Write the summary .txt file\n",
    "        output_file.write(adf_summary_str + \"\\n\")\n",
    "        output_file.write(ljung_box_summary_str + \"\\n\")\n",
    "        output_file.write(\"\\n\" + \"=\"*50 + \"\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geopy38",
   "language": "python",
   "name": "geopy38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
